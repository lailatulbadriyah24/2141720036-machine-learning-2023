{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lailatulbadriyah24/2141720036-machine-learning-2023/blob/main/praktikum-02-tugas-praktikum.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZSra1GNFAhSS"
      },
      "source": [
        "# **Praktikum 2: Generator Teks dengan RNN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7_2PVlhAp6b"
      },
      "source": [
        "## **Setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gC5xAozcPMm5"
      },
      "source": [
        "### **Import TensorFlow**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dUFprmpMPQxM"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRdVNQftPWdx"
      },
      "source": [
        "### **Download Dataset Shakespeare**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v8juYg4gParT"
      },
      "outputs": [],
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sk7AVDG5PqO5"
      },
      "source": [
        "### **Load Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf72ysIBPnZS",
        "outputId": "63977569-80cf-4635-9b97-b885052ff4ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ],
      "source": [
        "# Membaca teks dari file menggunakan mode 'rb' (binary mode) dan mendekode dengan encoding 'utf-8'\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Panjang teks adalah jumlah karakter dalam teks tersebut\n",
        "print(f'Length of text: {len(text)} characters')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol6z_nd1PwL4",
        "outputId": "143b311f-3e88-449a-c65b-1c96c3c65539"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Mencetak 250 karakter pertama dalam teks\n",
        "print(text[:250])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtzwyfLwP5h0",
        "outputId": "1dbb4940-a21a-42af-e15d-061aa8f743f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "65 unique characters\n"
          ]
        }
      ],
      "source": [
        "# Mengidentifikasi karakter-karakter unik dalam teks\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "# Mencetak jumlah karakter unik\n",
        "print(f'{len(vocab)} unique characters')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-W3jyaHP-jp"
      },
      "source": [
        "## **Olah Teks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcDKq9kmQBLQ"
      },
      "source": [
        "### **Vectorize Teks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NJ7zDYbQFcy"
      },
      "source": [
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDBxzkrQKsA",
        "outputId": "c2401411-cd8c-4f03-eb2c-df73a627ee2f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Daftar teks contoh\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "# Memecah teks menjadi karakter-karakter Unicode\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "# Menampilkan hasil karakter-karakter Unicode\n",
        "chars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxWcI0H2QUw0"
      },
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "veQAl0_IQY8q"
      },
      "outputs": [],
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi karakter menjadi ID numerik\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab),  # Daftar karakter-karakter yang ingin diindeks\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fx7lpw8-QcM3"
      },
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c1g-evjQhGS",
        "outputId": "7f68a9bd-a908-438f-e7c2-fc329d6f3573"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Mengonversi karakter-karakter Unicode menjadi ID numerik\n",
        "ids = ids_from_chars(chars)\n",
        "\n",
        "# Menampilkan hasil ID numerik\n",
        "ids"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME_l5PHOQpdR"
      },
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode\n",
        "`tf.keras.layers.StringLookup(..., invert=True)`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WwZ30hnfQwoR"
      },
      "outputs": [],
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi ID numerik ke karakter-karakter Unicode\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(),  # Menggunakan vocabulary yang telah diindeks sebelumnya\n",
        "    invert=True,  # Mengatur invert ke True untuk mengonversi kembali dari ID ke karakter\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1UwK4TjQ07J"
      },
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter `tf.RaggedTensor`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkkMaj34Q4AI",
        "outputId": "0d347ee5-4d29-4460-eaab-9feba2b9caf4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZECFZ3kQ_yo"
      },
      "outputs": [],
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CExDQMTwRFSe"
      },
      "source": [
        "## **Prediksi**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xygMSpKLRIgZ"
      },
      "source": [
        "### **Membuat Trianing Set dan Target**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDGcG_FjRQMs",
        "outputId": "b1815609-c3ef-4117-ec2a-1b8b4ec4c13e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvyfN2thRVoN"
      },
      "outputs": [],
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1BB9b9WRYVh",
        "outputId": "c409333c-3aef-4c0a-b831-79faaf34b5ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ],
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJVh5A5sRfaN"
      },
      "outputs": [],
      "source": [
        "seq_length = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g0Ujf0pRj5M"
      },
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x23Xhs9RkwQ",
        "outputId": "c93d0f33-d904-4b30-a714-3be5ad23108b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ],
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mnu7qzuMRnFP"
      },
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHzIPIE4RoB8",
        "outputId": "45a36836-ca74-4a23-a918-eb8544b48e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFKNsuSQR2yP"
      },
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFrhhXHJR3yL"
      },
      "outputs": [],
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4JjXTHBR7be",
        "outputId": "29311f0b-5043-4cd9-8587-9711cca3cd86"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhQ2Oy2iR8M7"
      },
      "outputs": [],
      "source": [
        "dataset = sequences.map(split_input_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjbMBcM-R_Bv",
        "outputId": "7c597519-f63a-4f24-d3ed-29cf00f521bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ],
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-naOjirSSMSn"
      },
      "source": [
        "### **Membuat Batch Training**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ZuuXPD3SP7m"
      },
      "source": [
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r7F3Z-hSYyR",
        "outputId": "88822678-0770-4fcd-e381-072b53ecb1b8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Batch size (ukuran batch) yang digunakan selama pelatihan\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size (ukuran buffer) untuk mengacak urutan dataset\n",
        "# TensorFlow data dirancang untuk bekerja dengan urutan yang mungkin tak terbatas,\n",
        "# sehingga tidak mencoba untuk mengacak seluruh urutan di dalam memori.\n",
        "# Sebaliknya, ia mempertahankan buffer di mana ia mengacak elemen.\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Mengonfigurasi dataset dengan mengacak urutan, mengatur ukuran batch,\n",
        "# dan menggunakan prefetch untuk optimalisasi\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)  # Mengacak urutan dataset\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)  # Mengatur ukuran batch dengan menghapus sisa data yang tidak cukup untuk satu batch\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)  # Menggunakan prefetch untuk optimalisasi\n",
        ")\n",
        "\n",
        "# Menampilkan dataset yang telah dikonfigurasi\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNKbrvteSa3v"
      },
      "source": [
        "### **Buat Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJxbIwxjSkOG"
      },
      "outputs": [],
      "source": [
        "# Jumlah kata dalam vocabulary pada lapisan StringLookup\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# Dimensi embedding\n",
        "embedding_dim = 256\n",
        "\n",
        "# Jumlah unit RNN (Recurrent Neural Network)\n",
        "rnn_units = 1024"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DydDIKuASqjF"
      },
      "outputs": [],
      "source": [
        "# Mendefinisikan kelas model khusus MyModel\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "\n",
        "    # Lapisan embedding untuk mengonversi ID numerik menjadi vektor embedding\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # Lapisan GRU (Gated Recurrent Unit) dengan return_sequences dan return_state\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "\n",
        "    # Lapisan dense (sepenuhnya terhubung) dengan vocab_size output\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "\n",
        "    # Menggunakan lapisan embedding\n",
        "    x = self.embedding(x, training=training)\n",
        "\n",
        "    if states is None:\n",
        "      # Mendapatkan initial_state dari lapisan GRU jika states adalah None\n",
        "      states = self.gru.get_initial_state(x)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan GRU\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan dense\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      # Mengembalikan output dan states jika return_state adalah True\n",
        "      return x, states\n",
        "    else:\n",
        "      # Mengembalikan hanya output jika return_state adalah False\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3judqwFWSwSc"
      },
      "outputs": [],
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,  # Jumlah kata dalam vocabulary\n",
        "    embedding_dim=embedding_dim,  # Dimensi embedding\n",
        "    rnn_units=rnn_units  # Jumlah unit dalam lapisan GRU\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6_3dZu1TRHx"
      },
      "source": [
        "### **Uji Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXejIFiBTTVv",
        "outputId": "58550ff5-ef21-46fc-cc32-235b24fd5957"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ],
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtiHr-0aTVK2",
        "outputId": "1cac514f-eb95-4029-b44c-d7613e427bf0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     multiple                  16896     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 multiple                  3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYHNdbLGTgQx"
      },
      "outputs": [],
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices= tf.squeeze(sampled_indices, axis=-1).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xYyKv1TiVL",
        "outputId": "e1cc608e-1276-415f-c913-73a0300f6695"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([62, 60, 31, 62, 13, 13,  0, 17, 23, 56,  5, 51, 61, 33,  4, 53, 49,\n",
              "        5, 57, 11, 45, 28, 36, 60, 48, 19, 28, 25,  7, 51, 61, 53,  7, 28,\n",
              "       55, 37,  0, 27, 31,  6, 28, 51,  4, 29, 56, 19, 40, 20, 23,  4, 63,\n",
              "       62, 65, 19, 62, 28, 49,  7, 40, 51, 61, 49, 42, 23, 26, 54, 59, 61,\n",
              "       34, 36, 50, 53,  8, 10, 27,  9, 41,  7, 44, 26, 20, 63, 31, 29,  1,\n",
              "       35, 58, 33, 29, 60,  8, 49, 31, 17, 23, 37, 40, 18, 13, 36])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sampled_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBYtrOMKTlSg"
      },
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3lFhz1FTmOO",
        "outputId": "d6bfb308-1a4c-4fa2-82e9-b711fd61b8a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input:\n",
            " b\"ful time!\\n\\nCAPULET:\\nDeath, that hath ta'en her hence to make me wail,\\nTies up my tongue, and will no\"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"wuRw??[UNK]DJq&lvT$nj&r:fOWuiFOL,lvn,OpX[UNK]NR'Ol$PqFaGJ$xwzFwOj,alvjcJMotvUWkn-3N.b,eMGxRP\\nVsTPu-jRDJXaE?W\"\n"
          ]
        }
      ],
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CHU0EFcvTqhZ"
      },
      "source": [
        "### **Train Model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiEIJa9mTugb"
      },
      "source": [
        "### **Tambahan optimizer dan fungsi loss**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ianM1LzsTyZN"
      },
      "source": [
        "loss function `tf.keras.losses.sparse_categorical_crossentropy` standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag `from_logits`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r3NS4010Txiv"
      },
      "outputs": [],
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awXsdeo5T2_S",
        "outputId": "8e45f1d8-75bb-4f04-e55f-33448bbb6fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.19082, shape=(), dtype=float32)\n"
          ]
        }
      ],
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkVK_SRlT57q"
      },
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8oak6NTT66X",
        "outputId": "0e0584a6-3b38-4cc6-bcb7-12c1c58afe71"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "66.076965"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15l9xvf_T8Z4"
      },
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEzgfJ_fT9Ou"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAmC2i2MUAz6"
      },
      "source": [
        "### **Konfigurasi Checkpoints**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Et5FE1URUEVw"
      },
      "source": [
        "Gunakan `tf.keras.callbacks.ModelCheckpoint` untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5DaoAtKUCy3"
      },
      "outputs": [],
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1wfkMnSyUH4j"
      },
      "source": [
        "### **Lakukan Proses Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr2Prky1UKsm"
      },
      "outputs": [],
      "source": [
        "EPOCHS = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "b21Ke52aUMeI",
        "outputId": "b0b79d90-48de-4ade-b117-2cec6e376294"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 604s 4s/step - loss: 2.5689\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 600s 3s/step - loss: 1.9674\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 598s 3s/step - loss: 1.7002\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 599s 3s/step - loss: 1.5465\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 600s 3s/step - loss: 1.4513\n",
            "Epoch 6/10\n",
            "168/172 [============================>.] - ETA: 13s - loss: 1.3852"
          ]
        }
      ],
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpRHmPcKUb1d"
      },
      "source": [
        "### **Generate Teks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQKIdpGNVhNY"
      },
      "source": [
        "Berikut ini membuat prediksi satu langkah:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJ0D-kcDVh6d"
      },
      "outputs": [],
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDJ5Yg8AVkwg"
      },
      "outputs": [],
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWcHnIK2Vpka",
        "outputId": "12410202-d259-433c-ce64-e7d72ff25f29"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "A fellow--\n",
            "Five fire, sir! where is Paul'd Clarence, being good a\n",
            "chatian to have calm'd in patience, thus I play.\n",
            "\n",
            "OXFORD:\n",
            "Now, sir, by yours, nay, my horse: give my bath you are.\n",
            "When teacher you under thyself he, my own pass\n",
            "And hide upon thy bosomer for us.\n",
            "\n",
            "Nousant: flictering, she should be warrant a wood\n",
            "Dook my nurse; for Northumberland, is the Tower:\n",
            "The gheen out of them and thy letters answer off.\n",
            "What is the trouble own of her; belike him a\n",
            "cause.\n",
            "\n",
            "POLIXENES:\n",
            "He must say, sir;\n",
            "But trud upon thy news?\n",
            "Before I may purchase you, my harbonies in.\n",
            "\n",
            "QUEEN MARGARET:\n",
            "Well heard the strenger be my dispostryurn have.\n",
            "\n",
            "ESCALUS:\n",
            "Call it we may dream or lose their weeps. They they parting with\n",
            "I should have forget for tham for't?\n",
            "If you lip still report of the abents,\n",
            "And was a little paradies, and my underfares\n",
            "Of worlding careless fairy and forband\n",
            "Slance are rud own heabless.\n",
            "Go like a gubs o'er; make kiss my master ask you as\n",
            "your grace grace no less smile and stand with tears,\n",
            "An \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.177626609802246\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20crZVvJVuYs",
        "outputId": "7e6feeb7-655d-4eec-e32d-8206fe7f86b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nJoin night, my lord; you were a prison; fellow,\\nAnt say, indeed; 'twere so defend the eft,\\n\\nAUThis man: his name? see the pleasant tale all my dear hand?\\nThen be here baldied mife and misersh?\\n\\nROMEO:\\nNo,\\nAnd then my lades, arm my brother biggers;\\nUnless this true king, it is yours. and\\nthey straight intents, sleweth as they are so.\\n\\nSLY:\\nPlease; Come, he's a woman bring my dangerous to me:\\nI have for't, being beleand, and moves as my unthat readies,\\nThom for the fish, boy in the shadefolding asking,\\nOpholour of happily make the matter,\\nTranio, paunt, a feast; 'tis a pies of self\\nthem: had it them foes.\\n\\nMISTREPS OF GARTES:\\nThey in tading so she farewell:\\nWhen he is a bark? Was this? 'Bounds! why, my masters to you;\\nSet it your chance procousion.\\n\\nLADY ANNE:\\nThou hast got them fited: friar, why have and mine!\\nFarewell, sister hath out Lilion betwill\\nBesum hail.\\nBut don, the keeper of Norfolk, shake us before.\\n\\nKING EDWARD IV:\\nAway, you regand; Rescite unto the war: this is held\\nThe pr\"\n",
            " b\"ROMEO:\\nAs good heart!\\nShame and go our points, I pray thee, here be gone.\\n\\nRATCLIFF:\\nCare is in ten thousand time should be the breath of death;\\nEven in mistorts by a daunted of a lear.\\nDetence, is not receive above, that face\\nIs rickle face and subacces? which now,\\nMade pass have brokes the paralty are our father is buried\\nHere's that prisoners.\\n\\nCORIOLANUS:\\nYou would swear\\nTo close ourselves made of kissing with my land.\\n\\nCATESBY:\\nHis incled my valiant cause\\nIn hasty bad, more pawn, as mine own place,\\nEven that I have left them good ach\\nOf repeal'd by a feaster presence then with by so feast,\\nAnd therefore was young beard, for they in here\\nSevone unto a follower than my valour,\\nIf would be fairer than my weaping Mars! I have a his\\nTo fale, for maiden, we clain believe them accused.\\nWith ill-part us?\\n\\nMENENIUS:\\nAy, what you shall pray?\\n\\nPETRUCHIO:\\nGive me them another? what he stends such a mise again,\\nCall hated and sparl of mortal, foun ill-bawds,\\nThe head of Rome had bleed his garden per\"\n",
            " b\"ROMEO:\\nOut of his enompericy, bell i' love?\\nO here they calm all Richmond?\\n\\nLARY ANNE:\\nWhere is the sea? farewell, hold, and poor ups.\\n\\nLUCENTIO:\\nHis brother tears, and lost his numbers of my forby, or see\\n\\nSATUS:\\nGrace and go,\\n\\nPAULINA:\\nForget, so, we shall not so: a bart!\\n\\nThird Servingman:\\nWhy, then where is it righ'd me?\\n\\nRICHARD:\\nAy, that thou canst not, let them much stave be as up,\\nFrom them, and farewell to account, sicrity for thy\\nIntoges; because she was a wife,\\nWith wisdom from many times shall speak another's blemis.\\nBesidring, by what your grandsmit or I am\\nI, no, not to be ring of kissing ood,\\nAs franith a short sed that I do im:\\nIs good me my master lies and head: I am spent\\nParage our ladys, malinine and by back.\\nIf thou me behold?\\n\\nGRUMIO:\\nI know your mide is speak.\\n\\nCORIOLANUS:\\nWhy, sir, now thy valours: savica laughter for his untershand.\\n\\nCAPULET:\\nWell, from me, sister, what paid it should go?\\n\\nDUKE VINCENTIO:\\nWhat must I do?\\n\\nPost:\\nPardon, my reposiness, master;\\nAnd slee\"\n",
            " b\"ROMEO:\\nThis foul way?\\nWe'll attend it.\\n\\nMISTRESS OVERDONE:\\nThou dribsts that I have found my father's death,\\nAnd tell me prepared, do; fet it being in law,\\nWill give us beat from touch our bonish marriage,\\nEven thence calls up on court, grieves. But, O, they must sleep,\\nI sent it were; for the falseon as he great devenger\\nSheph me-tongues upon himself-kingly wreech all yield!\\nbut I bid must make expured me are alike.\\nGo''t be the Lord Silrihe Strike sorrow, good father;\\nThou camest not their function! why, they say,\\nHe Talkins have not afore that name of sleep,\\nAnd pray the worldge of unproud image\\nTo wait upon your hate and would pluck their\\nvalies, here is our marriage, behold him our head,\\nAnd boar me loss, the precious majesty\\nI am not saint up grubs and talk, and lap's time, light he loss--\\nI have heard them near against the wolf: I warrant,\\nUnless you will emplock your eye?\\n\\nFLORIZEL:\\nBut: see,\\nSuy of her! Say you?\\n\\nPROSPERO:\\n\\nGLOUCESTER:\\nThe giddy clock my-ported backeth wounds not th\"\n",
            " b\"ROMEO:\\nThe meeting of true death; But is thy matter\\nFor the orisor of reoporicious eye;\\nBut The bed melles pleased, the beaning land\\nOf this dishonour to prison, and most sworn\\nWith safety of his thatshor, my lord prigst,\\nLoved by the very revement friendly perch\\nThe lands plainly fly Torturs in part enduince\\nHave twenty pale about me.\\nAh, time, the matter. Perumal and me;\\nBright have been in crual orifles, widow, past; an\\nyou gop our thursday house in thiuse.\\n\\nCLAUDIO:\\nThe king! they come! good bad, seem town:\\nAnd, as I tell thee my lord?\\n\\nLEONTES:\\nIf that this mistress York?\\n\\nPost:\\nI do chol.\\n\\nClARUS:\\nIf thou dost beseech it?\\n\\nSecond OF GAUNT:\\nGod yet one over that grief backet's widow:\\nWill you can be a party. Bapace upon,\\nWas worth in your faurt! and how she sad\\nAs his war becomes than hear she hath,\\nThese stands in the man is rignest hence to Bolixion.\\n\\nBAPTISTA:\\nWhy, hang my chancion?\\nO, pray, if you have proportion with a nad,'-\\nwith one may be obstranded embose them and make\\nWith our\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.323456048965454\n"
          ]
        }
      ],
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BnIQu9_FVzFf"
      },
      "source": [
        "### **Ekspor Model Generator**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4SCw-2fV363",
        "outputId": "33ce046f-e24b-4d16-bbb9-a5bfdf0db12f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7c430fc7c670>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ],
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVVLwLO8V5rR",
        "outputId": "e2b6a393-eacc-4b9a-f67b-eb68420bc0b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ROMEO:\n",
            "Thy birth degree there or no more.\n",
            "\n",
            "VOLUMNIA:\n",
            "Ay, march; warwick, inclusanate, madam.\n",
            "\n",
            "ROMEO:\n",
            "Who b\n"
          ]
        }
      ],
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OsKUeogIdioh"
      },
      "source": [
        "# **Tugas Praktikum**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aUZK_lhGdoA-"
      },
      "source": [
        "Prosedur pelatihan pada praktikum 2 merupakan prosedur sederhana, yang tidak memberi Anda banyak kendali. Model ini menggunakan \"teacher-forcing\" yang mencegah prediksi buruk diumpankan kembali ke model, sehingga model tidak pernah belajar untuk pulih dari kesalahan. Jadi, setelah Anda melihat cara menjalankan model secara manual, selanjutnya Anda akan mengimplementasikan custom loop pelatihan. Hal ini memberikan titik awal jika, misalnya, Anda ingin menerapkan pembelajaran kurikulum untuk membantu menstabilkan keluaran open-loop model. Bagian terpenting dari loop pelatihan khusus adalah fungsi langkah pelatihan.\n",
        "\n",
        "Gunakan `tf.GradientTape` untuk men track nilai gradient. Anda dapat mempelajari lebih lanjut tentang pendekatan ini dengan membaca `eager execution guide`.\n",
        "\n",
        "Prosedurnya adalah:\n",
        "1. Jalankan Model dan hitung loss dengan `tf.GradientTape`.\n",
        "2. Hitung update dan terapkan pada model dengan optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QnA9TlJgDnO"
      },
      "outputs": [],
      "source": [
        "class CustomTraining(MyModel):\n",
        " @tf.function\n",
        " def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "        predictions = self(inputs, training=True)\n",
        "        loss = self.loss(labels, predictions)\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcVpndk9gI4I"
      },
      "source": [
        "Kode diatas menerapkan `train_step` method sesuai dengan  `Keras' train_step conventions`. Ini opsional, tetapi memungkinkan Anda mengubah perilaku langkah pelatihan dan tetap menggunakan keras `Model.compile` and `Model.fit methods`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkHzj9SOgKVz"
      },
      "outputs": [],
      "source": [
        "model = CustomTraining(\n",
        "     vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "     embedding_dim=embedding_dim,\n",
        "     rnn_units=rnn_units)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EN2PlZ_HgQeM"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXo8tekFgUCf",
        "outputId": "84fa0f6d-e814-42bc-c764-2746034f3af9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "172/172 [==============================] - 23s 70ms/step - loss: 2.6993\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c43219963e0>"
            ]
          },
          "execution_count": 93,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(dataset, epochs=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vq6-lAU7gc-h"
      },
      "source": [
        "Atau jika ingin lebih mengetahui dalamnya, kita bisa membuat custom training loop sendiri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4eAUrwLgcjG",
        "outputId": "625ef31c-c9c0-49d6-d51a-a184150a5ca6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1579\n",
            "Epoch 1 Batch 50 Loss 2.0524\n",
            "Epoch 1 Batch 100 Loss 1.9739\n",
            "Epoch 1 Batch 150 Loss 1.8555\n",
            "\n",
            "Epoch 1 Loss: 1.9813\n",
            "Time taken for 1 epoch 14.38 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8018\n",
            "Epoch 2 Batch 50 Loss 1.7510\n",
            "Epoch 2 Batch 100 Loss 1.6838\n",
            "Epoch 2 Batch 150 Loss 1.6812\n",
            "\n",
            "Epoch 2 Loss: 1.7058\n",
            "Time taken for 1 epoch 12.08 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5939\n",
            "Epoch 3 Batch 50 Loss 1.6095\n",
            "Epoch 3 Batch 100 Loss 1.5629\n",
            "Epoch 3 Batch 150 Loss 1.5461\n",
            "\n",
            "Epoch 3 Loss: 1.5465\n",
            "Time taken for 1 epoch 12.11 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4616\n",
            "Epoch 4 Batch 50 Loss 1.4688\n",
            "Epoch 4 Batch 100 Loss 1.4376\n",
            "Epoch 4 Batch 150 Loss 1.4129\n",
            "\n",
            "Epoch 4 Loss: 1.4476\n",
            "Time taken for 1 epoch 12.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.4095\n",
            "Epoch 5 Batch 50 Loss 1.3983\n",
            "Epoch 5 Batch 100 Loss 1.3462\n",
            "Epoch 5 Batch 150 Loss 1.3693\n",
            "\n",
            "Epoch 5 Loss: 1.3797\n",
            "Time taken for 1 epoch 54.81 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3348\n",
            "Epoch 6 Batch 50 Loss 1.3437\n",
            "Epoch 6 Batch 100 Loss 1.3512\n",
            "Epoch 6 Batch 150 Loss 1.3827\n",
            "\n",
            "Epoch 6 Loss: 1.3281\n",
            "Time taken for 1 epoch 12.39 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2920\n",
            "Epoch 7 Batch 50 Loss 1.2945\n",
            "Epoch 7 Batch 100 Loss 1.2770\n",
            "Epoch 7 Batch 150 Loss 1.2785\n",
            "\n",
            "Epoch 7 Loss: 1.2836\n",
            "Time taken for 1 epoch 12.05 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2312\n",
            "Epoch 8 Batch 50 Loss 1.2281\n",
            "Epoch 8 Batch 100 Loss 1.2559\n",
            "Epoch 8 Batch 150 Loss 1.2567\n",
            "\n",
            "Epoch 8 Loss: 1.2429\n",
            "Time taken for 1 epoch 12.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.1921\n",
            "Epoch 9 Batch 50 Loss 1.2066\n",
            "Epoch 9 Batch 100 Loss 1.2448\n",
            "Epoch 9 Batch 150 Loss 1.1992\n",
            "\n",
            "Epoch 9 Loss: 1.2028\n",
            "Time taken for 1 epoch 12.07 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1291\n",
            "Epoch 10 Batch 50 Loss 1.1634\n",
            "Epoch 10 Batch 100 Loss 1.2010\n",
            "Epoch 10 Batch 150 Loss 1.1973\n",
            "\n",
            "Epoch 10 Loss: 1.1628\n",
            "Time taken for 1 epoch 43.69 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "EPOCHS = 10\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "      logs = model.train_step([inp, target])\n",
        "      mean.update_state(logs['loss'])\n",
        "\n",
        "      if batch_n % 50 == 0:\n",
        "         template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "         print(template)\n",
        "\n",
        " # saving (checkpoint) the model every 5 epochs\n",
        "      if (epoch + 1) % 5 == 0:\n",
        "         model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAAXWAktm805"
      },
      "source": [
        "**Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs5OMckAsQAS"
      },
      "source": [
        "Pada praktikum 2, digunakan pendekatan pelatihan yang lebih umum dan sederhana dengan metode `model.fit` yang sudah terintegrasi dengan TensorFlow. Metode ini mengelola sebagian besar aspek pelatihan, termasuk perhitungan loss, perhitungan gradien, dan pembaruan bobot model secara otomatis.\n",
        "\n",
        "Sementara itu, pada kode tugas prakikum, digunakan pendekatan pelatihan yang lebih spesifik dan kompleks. Dalam pendekatan ini, didefinisikan metode `train_step` dalam model turunan yang mengatur dengan jelas perhitungan loss, perhitungan gradien, dan pembaruan bobot model. Selain itu, digunakan objek `tf.metrics.Mean` untuk menghitung rata-rata loss selama pelatihan. Pendekatan ini memberikan lebih banyak kemampuan untuk mengendalikan dan menyesuaikan pelatihan model, yang sangat berguna untuk tugas-tugas yang membutuhkan penyesuaian yang spesifik.\n",
        "\n",
        "Jadi secara keseluruhan, perbedaan utama terletak pada pendekatan pelatihan yang digunakan, di mana kode pada tugas praktikum memberikan tingkat kontrol yang lebih tinggi dan lebih banyak opsi kustomisasi dalam proses pelatihan model."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyOXr0RN6xlyydHyTi6uR8Rn",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
