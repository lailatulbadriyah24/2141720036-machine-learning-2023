{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPP+Ay7KjXuAhbeX0Bwx4UL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lailatulbadriyah24/2141720036-machine-learning-2023/blob/main/praktikum-02.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Praktikum 1: Generator Teks dengan RNN**"
      ],
      "metadata": {
        "id": "ZSra1GNFAhSS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Setup**"
      ],
      "metadata": {
        "id": "N7_2PVlhAp6b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Import TensorFlow**"
      ],
      "metadata": {
        "id": "gC5xAozcPMm5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "dUFprmpMPQxM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Download Dataset Shakespeare**"
      ],
      "metadata": {
        "id": "XRdVNQftPWdx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt','https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8juYg4gParT",
        "outputId": "e8820cd9-4870-4253-9c7e-cb027b19801f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n",
            "1115394/1115394 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Load Data**"
      ],
      "metadata": {
        "id": "sk7AVDG5PqO5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membaca teks dari file menggunakan mode 'rb' (binary mode) dan mendekode dengan encoding 'utf-8'\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "\n",
        "# Panjang teks adalah jumlah karakter dalam teks tersebut\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vf72ysIBPnZS",
        "outputId": "47d19705-22e0-484c-ce2c-73089cdfac41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mencetak 250 karakter pertama dalam teks\n",
        "print(text[:250])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ol6z_nd1PwL4",
        "outputId": "38e62751-6609-4908-8f1e-4a02ed5eacad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengidentifikasi karakter-karakter unik dalam teks\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "# Mencetak jumlah karakter unik\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtzwyfLwP5h0",
        "outputId": "53ca854b-d4c9-45c8-f31e-179a9ed3f34f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Olah Teks**"
      ],
      "metadata": {
        "id": "F-W3jyaHP-jp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Vectorize Teks**"
      ],
      "metadata": {
        "id": "QcDKq9kmQBLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum training, Anda perlu mengonversi string menjadi representasi numerik. tf.keras.layers.StringLookup dapat mengubah setiap karakter menjadi ID numerik. Caranya adalah teks akan dipecah menjadi token terlebih dahulu."
      ],
      "metadata": {
        "id": "2NJ7zDYbQFcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Daftar teks contoh\n",
        "example_texts = ['abcdefg', 'xyz']\n",
        "\n",
        "# Memecah teks menjadi karakter-karakter Unicode\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "\n",
        "# Menampilkan hasil karakter-karakter Unicode\n",
        "chars"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQDBxzkrQKsA",
        "outputId": "b8f1de4a-00f6-4d25-fdd5-5d670090a719"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "sekarang buat tf.keras.layers.StringLookup layer:"
      ],
      "metadata": {
        "id": "qxWcI0H2QUw0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi karakter menjadi ID numerik\n",
        "ids_from_chars = tf.keras.layers.StringLookup(\n",
        "    vocabulary=list(vocab),  # Daftar karakter-karakter yang ingin diindeks\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ],
      "metadata": {
        "id": "veQAl0_IQY8q"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "perintah diatas mengconvert token menjadi id"
      ],
      "metadata": {
        "id": "Fx7lpw8-QcM3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mengonversi karakter-karakter Unicode menjadi ID numerik\n",
        "ids = ids_from_chars(chars)\n",
        "\n",
        "# Menampilkan hasil ID numerik\n",
        "ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-c1g-evjQhGS",
        "outputId": "bb9d41c5-5958-42d0-f718-8b21e1ff9268"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Karena tujuan tutorial ini adalah untuk menghasilkan teks, penting juga untuk membalikkan representasi ini. Untuk ini Anda dapat menggunakan kode\n",
        "`tf.keras.layers.StringLookup(..., invert=True)`."
      ],
      "metadata": {
        "id": "ME_l5PHOQpdR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Membuat lapisan StringLookup untuk mengonversi ID numerik ke karakter-karakter Unicode\n",
        "chars_from_ids = tf.keras.layers.StringLookup(\n",
        "    vocabulary=ids_from_chars.get_vocabulary(),  # Menggunakan vocabulary yang telah diindeks sebelumnya\n",
        "    invert=True,  # Mengatur invert ke True untuk mengonversi kembali dari ID ke karakter\n",
        "    mask_token=None  # Token masking (jika ada), dalam hal ini, tidak ada masking\n",
        ")"
      ],
      "metadata": {
        "id": "WwZ30hnfQwoR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lapisan ini mengconvert kembali karakter dari vektor ID, dan mengembalikannya sebagai karakter `tf.RaggedTensor`:"
      ],
      "metadata": {
        "id": "s1UwK4TjQ07J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkkMaj34Q4AI",
        "outputId": "a143c82d-c89e-4111-fd4e-f430114b4d0c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "  return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "mZECFZ3kQ_yo"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Prediksi**"
      ],
      "metadata": {
        "id": "CExDQMTwRFSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Membuat Trianing Set dan Target**"
      ],
      "metadata": {
        "id": "xygMSpKLRIgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDGcG_FjRQMs",
        "outputId": "8e6c6695-9f4b-4754-b299-d0993d804160"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "XvyfN2thRVoN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "  print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k1BB9b9WRYVh",
        "outputId": "0d99146d-121b-4fce-df2e-7ce9d04e7688"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "wJVh5A5sRfaN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Metode batch memungkinkan Anda dengan mudah mengonversi karakter individual ini menjadi urutan ukuran yang diinginkan."
      ],
      "metadata": {
        "id": "4g0Ujf0pRj5M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3x23Xhs9RkwQ",
        "outputId": "2527f8e0-76fa-406a-d830-e0d7eafa8e7a"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "akan lebih mudah untuk melihat apa yang dilakukan jika Anda menggabungkan token kembali menjadi string:"
      ],
      "metadata": {
        "id": "mnu7qzuMRnFP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHzIPIE4RoB8",
        "outputId": "5cc55244-45d6-4939-e710-0128e15cffdd"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Untuk pelatihan, Anda memerlukan kumpulan data pasangan (input, label). Dimana input dan label merupakan urutan. Pada setiap langkah waktu, inputnya adalah karakter saat ini dan labelnya adalah karakter berikutnya. Berikut adalah fungsi yang mengambil urutan sebagai masukan, menduplikasi, dan menggesernya untuk menyelaraskan masukan dan label untuk setiap langkah waktu:"
      ],
      "metadata": {
        "id": "JFKNsuSQR2yP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "  input_text = sequence[:-1]\n",
        "  target_text = sequence[1:]\n",
        "  return input_text, target_text"
      ],
      "metadata": {
        "id": "GFrhhXHJR3yL"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4JjXTHBR7be",
        "outputId": "de2e73b1-649e-4e2c-f967-ebfa9b2e6d73"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "AhQ2Oy2iR8M7"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "  print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "  print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjbMBcM-R_Bv",
        "outputId": "2d62a2fe-aaae-45cf-adc6-743b3db07c40"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Membuat Batch Training**"
      ],
      "metadata": {
        "id": "-naOjirSSMSn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Anda menggunakan tf.data untuk membagi teks menjadi sequence yang dapat diatur. Namun sebelum memasukkan data ini ke dalam model, Anda perlu mengacak data dan mengemasnya ke dalam batch."
      ],
      "metadata": {
        "id": "3ZuuXPD3SP7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size (ukuran batch) yang digunakan selama pelatihan\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Buffer size (ukuran buffer) untuk mengacak urutan dataset\n",
        "# TensorFlow data dirancang untuk bekerja dengan urutan yang mungkin tak terbatas,\n",
        "# sehingga tidak mencoba untuk mengacak seluruh urutan di dalam memori.\n",
        "# Sebaliknya, ia mempertahankan buffer di mana ia mengacak elemen.\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "# Mengonfigurasi dataset dengan mengacak urutan, mengatur ukuran batch,\n",
        "# dan menggunakan prefetch untuk optimalisasi\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)  # Mengacak urutan dataset\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)  # Mengatur ukuran batch dengan menghapus sisa data yang tidak cukup untuk satu batch\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)  # Menggunakan prefetch untuk optimalisasi\n",
        ")\n",
        "\n",
        "# Menampilkan dataset yang telah dikonfigurasi\n",
        "dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2r7F3Z-hSYyR",
        "outputId": "e76002dc-73af-4269-c295-a10793842763"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Buat Model**"
      ],
      "metadata": {
        "id": "MNKbrvteSa3v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Jumlah kata dalam vocabulary pada lapisan StringLookup\n",
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "# Dimensi embedding\n",
        "embedding_dim = 256\n",
        "\n",
        "# Jumlah unit RNN (Recurrent Neural Network)\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "uJxbIwxjSkOG"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mendefinisikan kelas model khusus MyModel\n",
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "\n",
        "    # Lapisan embedding untuk mengonversi ID numerik menjadi vektor embedding\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "    # Lapisan GRU (Gated Recurrent Unit) dengan return_sequences dan return_state\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "\n",
        "    # Lapisan dense (sepenuhnya terhubung) dengan vocab_size output\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "\n",
        "    # Menggunakan lapisan embedding\n",
        "    x = self.embedding(x, training=training)\n",
        "\n",
        "    if states is None:\n",
        "      # Mendapatkan initial_state dari lapisan GRU jika states adalah None\n",
        "      states = self.gru.get_initial_state(x)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan GRU\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "\n",
        "    # Melakukan langkah propagasi pada lapisan dense\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      # Mengembalikan output dan states jika return_state adalah True\n",
        "      return x, states\n",
        "    else:\n",
        "      # Mengembalikan hanya output jika return_state adalah False\n",
        "      return x"
      ],
      "metadata": {
        "id": "DydDIKuASqjF"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,  # Jumlah kata dalam vocabulary\n",
        "    embedding_dim=embedding_dim,  # Dimensi embedding\n",
        "    rnn_units=rnn_units  # Jumlah unit dalam lapisan GRU\n",
        ")"
      ],
      "metadata": {
        "id": "3judqwFWSwSc"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uji Model**"
      ],
      "metadata": {
        "id": "z6_3dZu1TRHx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXejIFiBTTVv",
        "outputId": "07da1fb3-c036-4b9b-b3b0-fddec260d1a1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtiHr-0aTVK2",
        "outputId": "482deabd-62d5-407a-eba0-ffafff5cd6e8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       multiple                  16896     \n",
            "                                                                 \n",
            " gru (GRU)                   multiple                  3938304   \n",
            "                                                                 \n",
            " dense (Dense)               multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices= tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "FYHNdbLGTgQx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9xYyKv1TiVL",
        "outputId": "ed30535b-32dc-4813-94f6-7815e9308670"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([42, 31,  6,  7, 50, 45,  0, 41, 23, 44, 40, 33, 50, 59, 50, 26, 44,\n",
              "       20, 35, 64, 29, 55, 51, 24,  3, 22, 52, 18, 15, 41, 15, 24, 20, 56,\n",
              "       45, 33, 56, 56, 11,  1, 33, 26, 28, 34,  9,  8, 52, 33, 14, 20, 38,\n",
              "       20,  8, 58, 39,  2, 36, 52, 57, 32,  0, 41,  8, 41, 65, 34,  0,  1,\n",
              "       62, 46, 46, 34,  3, 12, 46, 27, 55, 46, 23, 21, 11, 26, 38, 15, 22,\n",
              "        0, 18, 41,  3, 48, 47, 59, 37, 42, 62, 35, 55, 29, 15, 61])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dekode kode berikut untuk melihat teks yang diprediksi oleh model tidak terlatih ini:"
      ],
      "metadata": {
        "id": "vBYtrOMKTlSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3lFhz1FTmOO",
        "outputId": "120d6846-402c-4710-f020-dbeece4b7755"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b\"forbid that I should wish them sever'd\\nWhom God hath join'd together; ay, and 'twere pity\\nTo sunder \"\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"cR',kf[UNK]bJeaTktkMeGVyPplK!ImEBbBKGqfTqq:\\nTMOU.-mTAGYG-sZ WmrS[UNK]b-bzU[UNK]\\nwggU!;gNpgJH:MYBI[UNK]Eb!ihtXcwVpPBv\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Train Model**"
      ],
      "metadata": {
        "id": "CHU0EFcvTqhZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Tambahan optimizer dan fungsi loss**"
      ],
      "metadata": {
        "id": "FiEIJa9mTugb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "loss function `tf.keras.losses.sparse_categorical_crossentropy` standar berfungsi dalam kasus ini karena diterapkan di seluruh dimensi terakhir prediksi. Karena model Anda mengembalikan logits, Anda perlu mengatur flag `from_logits`."
      ],
      "metadata": {
        "id": "ianM1LzsTyZN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "r3NS4010Txiv"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awXsdeo5T2_S",
        "outputId": "8b47d0e9-c81a-464b-eb02-be8365cf3713"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1890783, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model yang baru diinisialisasi tidak boleh terlalu yakin dengan dirinya sendiri, semua log keluaran harus memiliki besaran yang sama. Untuk mengonfirmasi hal ini, Anda dapat memeriksa bahwa eksponensial dari loss rata-rata harus kira-kira sama dengan ukuran kosakata. Loss yang jauh lebih tinggi berarti model tersebut yakin akan jawaban yang salah, dan memiliki inisialisasi yang buruk:"
      ],
      "metadata": {
        "id": "LkVK_SRlT57q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8oak6NTT66X",
        "outputId": "52a65b4e-6764-44d0-cf09-59f60788802a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.96197"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasikan prosedur pelatihan menggunakan metode tf.keras.Model.compile. Gunakan tf.keras.optimizers.Adam dengan argumen default dan fungsi loss."
      ],
      "metadata": {
        "id": "15l9xvf_T8Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "gEzgfJ_fT9Ou"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Konfigurasi Checkpoints**"
      ],
      "metadata": {
        "id": "LAmC2i2MUAz6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Gunakan `tf.keras.callbacks.ModelCheckpoint` untuk memastikan bahwa checkpoint disimpan selama pelatihan:"
      ],
      "metadata": {
        "id": "Et5FE1URUEVw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Directory where the checkpoints will be saved\n",
        "checkpoint_dir = './training_checkpoints'\n",
        "# Name of the checkpoint files\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "f5DaoAtKUCy3"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lakukan Proses Training**"
      ],
      "metadata": {
        "id": "1wfkMnSyUH4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10"
      ],
      "metadata": {
        "id": "Tr2Prky1UKsm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b21Ke52aUMeI",
        "outputId": "d4cbe254-3e6f-4ad3-a082-ad6cd4af4b6f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "172/172 [==============================] - 15s 58ms/step - loss: 2.6928\n",
            "Epoch 2/10\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.9713\n",
            "Epoch 3/10\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 1.6898\n",
            "Epoch 4/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.5309\n",
            "Epoch 5/10\n",
            "172/172 [==============================] - 13s 62ms/step - loss: 1.4344\n",
            "Epoch 6/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.3682\n",
            "Epoch 7/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.3159\n",
            "Epoch 8/10\n",
            "172/172 [==============================] - 12s 61ms/step - loss: 1.2712\n",
            "Epoch 9/10\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 1.2292\n",
            "Epoch 10/10\n",
            "172/172 [==============================] - 14s 62ms/step - loss: 1.1887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Generate Teks**"
      ],
      "metadata": {
        "id": "GpRHmPcKUb1d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Berikut ini membuat prediksi satu langkah:"
      ],
      "metadata": {
        "id": "qQKIdpGNVhNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "qJ0D-kcDVh6d"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
      ],
      "metadata": {
        "id": "GDJ5Yg8AVkwg"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cWcHnIK2Vpka",
        "outputId": "234d54a0-3d15-4b44-fcb6-7388e0f77891"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Why, that, no Bontx; with it best warn,\n",
            "King Ricobonds with mine art to make\n",
            "O, Nappioly, as is nothing, but to stand again,\n",
            "The gokn nor play the wall: a high now being\n",
            "show'd, I'll warrant their way; whiles on me\n",
            "For me hath brought not one that clouds 'proot's\n",
            "jowerful, that I was here.\n",
            "\n",
            "PETRUCHIO:\n",
            "Ye remeetes which we give him not, sir? what:'\n",
            "Jeposter, that resposs the king's blood.\n",
            "\n",
            "BISHOP OF ELY:\n",
            "Romeo.\n",
            "\n",
            "CAMILLO:\n",
            "He had she fall and go.\n",
            "\n",
            "KATHARINA:\n",
            "We'll have bade done was, make way.\n",
            "\n",
            "NatreLIO:\n",
            "Thy folly, Right! Why that I do inhoct and house,\n",
            "That rich suffer' to put on prince,\n",
            "And that his own a rabs to grant her,\n",
            "And swift from many orn Agot:\n",
            "Preparable from this lamentations,\n",
            "Which he does sinken enemy may purthes\n",
            "But they were sent to but a horse!\n",
            "\n",
            "POLIXENES:\n",
            "know, yield my son: I'll have him\n",
            "farther, and set old man frinch the wing.\n",
            "\n",
            "WARWICK:\n",
            "Peace, do you more.\n",
            "\n",
            "POLIXENES:\n",
            "I power,\n",
            "But make my hearing of it hatket she I\n",
            "to little guard, fearful, sho draw that honsel'd:\n",
            "H \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.9527435302734375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time()\n",
        "states = None\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(1000):\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "result = tf.strings.join(result)\n",
        "end = time.time()\n",
        "print(result, '\\n\\n' + '_'*80)\n",
        "print('\\nRun time:', end - start)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20crZVvJVuYs",
        "outputId": "fe22e937-8ad7-42be-f541-a70244cfd987"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nWhat bring it to sat: his son--servire,\\nThat standed government and Warwick, and thy father\\nDispositions to see them come, which is his\\nstill back me word, leisure as he was any oqued\\nResent?' 'Trutching my lord, I'll but live away ty?\\nFarewell: this morning spira's tows of death;\\nAnd, witowords of Brancag's; even all the rack,\\nWe nare smilingly be said that have ta'en time\\nAnd yet run this faint, as if bearing my son,\\nVervip's persupt enjoy, my uncle Clarence, else\\nThoubs regard.\\n\\nFRIAR LAURENCE:\\nDo spoken, hence? and his new deeds,\\nThough the night of maze himself a haste,\\nDeath neighmons of Paris; gentle people\\nAction of dreadful scorn; no graced, serve\\nAnd in love palters from this cold with your dreams;\\nAnd when they shall resolve me joyal breath,\\nAnd break our tranions or't, Sunday, ballaged,\\nWith this grown better macks to deceive;\\nBut what feel more beasts of enter'd,\\nWe see, unuving idstence with down:\\nFor on forwards of necess'd withs.\\nThat she's me do consem, yourself,\\nIf y\"\n",
            " b\"ROMEO:\\nPeace! we, and he, own in wretchs,\\nBut lack tood Ritham: feel anony of thine;\\nThou matted by my flesh, and by,\\nSo set to honourable men!\\n\\nWARWICK:\\nFear you, grant thou shalt me.\\n\\nYORK:\\nThis wow he was mine own next banish'd from Peligane\\nTo make peace evil benelity, and cire benning,\\n'tis call'd me part more to show,\\nAnd give thee to them rather judge.\\n\\nLEONTES:\\nHow dope him, I speak not.\\n\\nSICINIUS:\\nThat spoil; and hast thou seem'd thee other?\\n\\nFirst Musician:\\nThis well not take him come to have them begn theeth of my promest.\\n\\nDUKE VINCENTIO:\\nIf God so, let me say. The times of heaven\\nAs ever may be news above man.\\n'Twixt that companation with her voice,\\nUnless an all their daughters rived. Go't on,\\nWhich, for the sines of my pinished Copes,\\nCan plubat true present' yieldest.\\n\\nShepherd:\\nWe'll lay my granes: how should you come to him.\\n\\nAUTOLYCUS:\\nI gentle heavens than: you shall I fear off\\nAge, where's the couns little writ to this world?\\nA God, Fray-were, nor sound. Lord Glimes of B\"\n",
            " b\"ROMEO:\\nProceed an hour, brother?\\n\\nANGELO:\\nAm now\\nI were abjoardly in requits; and call'd my content\\nAnd say: it pleaset i' the stamp'd.\\n\\nMENENIUS:\\n'Tis a while:\\nWhich you do strew thyself I'll lam\\nNow, slighen harron. That He comes him to thy head;\\nAs id no sword, save three,\\nThat All by changes? Didst yet yet mistress,\\nand not the King of him: does renowned we\\nshowe him, wherefore, Araze many giate,\\nfear'd to make gnat as these fields; tell her there;\\nFor the eyes of bent of other hamp\\nTo plainly maid o'er mine arr have;\\nAnd, to seek to abway my defiges,\\nSuch as theres, patient to his cholic, fair a hellow,\\nDead for mocks to see that name whose vows\\nDrown and o'er and make thy brother-blind-blessed length,\\nInte man indeed to look upon you:\\nLuly, go, and let him speak alone comes;\\nNow counsellor, yet knock,\\nTo have the beggar fell nobleman?\\n\\nCAPILLO:\\nI may be gone.\\n\\nESCALUS:\\nIren, my lord.\\n\\nLEONTES:\\nWhat's the rosidet? where depart!\\nAlaz, proceed bits no, i' the marriage more but stay.\\n\\nRIVE\"\n",
            " b\"ROMEO:\\nA hundred standable doing, a seiz\\nO exameness acters of man so wise.\\n\\nAETO:\\nGod say his hands and elder stars a saint,\\nImplimed and set where you see him?\\n\\nFirst Senator:\\nThere is eyer look in.\\n\\nRATCLIFF:\\nThou shalt not, Plant, good grief, and quickly mency,\\nWarquing all enemies, by calm to prove his part\\nWere consent to Angelo herlid:\\nThe case is nothing, ere I will to Oxform'd\\nWhich should seem blemied to sund Become a feast.\\n\\nTRANIO:\\nAnd then depiser, in this horse that sees\\nOf friends of noirs.\\n\\nPETRUCHIO:\\nThat can deliver and will'st mine, and two mildsible!\\n\\nPAULINA:\\nThat shall not\\nbe, or lay the banishment.\\n\\nMARCIUS:\\nTry o' the stone, our loss and what I emplain'd\\nAs shames to make them, by retort, the queen or good,\\nThat trubp'd me with one imposeth hence,\\nSo many made women or wore well contend:\\n'Tis simple son thy fabes, he!\\n\\nFirst Servingman:\\nLet me do not ever.\\n\\nBUSHINA:\\nPray, help, Signior Gremio;\\nWhat dost trous?\\n\\nMOPSA:\\nTrood of that I, she back within, because my broth\"\n",
            " b\"ROMEO:\\nO blament pity long rum. O post,\\nBut shall we should in persuries: shortly spiding short\\nNo stool upon your cause; and thank you, sir,\\nThan deadly pray for I know thou till't lone under them,\\nThan when the bat leans make away to learn with good-term\\nThe royal perpectiove a haluve win.\\n\\nDUKE OF YORK:\\nBelieve me,'s name, by your tend;\\nAnd seem me for that meddle weal at\\nDune o' the cares of nobleness; if thou lovest Rome,\\nPues him ourselves, and when his report her imposed\\nAnd holy little. God grant you well!\\nI never men, and arts your brower, son.\\n\\nWARWICK:\\nAlack, nothing; but he hath made a coward\\nOne of your friends, and nothing clabmed pale to be sear'd!\\nYet goes she will to dign of your\\nsees to be thus nothing on their peacie\\ncan pald again course.\\n\\nNumselves;\\nHe rences his pains should be much upon myself.\\n\\nLUCIO:\\nDarrant, and all eyes in yellows;\\nAnd warnisgs at your kind: yet, follow, I will, which is\\nher hence; having me have chastes remains\\nThan valour. O, yet Lewis both than \"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 4.693821430206299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Ekspor Model Generator**"
      ],
      "metadata": {
        "id": "BnIQu9_FVzFf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step')\n",
        "one_step_reloaded = tf.saved_model.load('one_step')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4SCw-2fV363",
        "outputId": "63a2ebcd-207c-4d21-9272-e06cf579c513"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7c439f323430>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None\n",
        "next_char = tf.constant(['ROMEO:'])\n",
        "result = [next_char]\n",
        "\n",
        "for n in range(100):\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states)\n",
        "  result.append(next_char)\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVVLwLO8V5rR",
        "outputId": "f6b2045c-6c7e-4414-a943-4f16edefb4c1"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Ah, tradiols me, on me, in that all, grace!\n",
            "They shall be put to do:\n",
            "I dreamt hew shou, and with a \n"
          ]
        }
      ]
    }
  ]
}